{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Real-world recommender systems are often composed of two stages:\n",
        "\n",
        "The retrieval stage is responsible for selecting an initial set of hundreds of candidates from all possible candidates. The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient.\n",
        "The ranking stage takes the outputs of the retrieval model and fine-tunes them to select the best possible handful of recommendations. Its task is to narrow down the set of items the user may be interested in to a shortlist of likely candidates."
      ],
      "metadata": {
        "id": "uwaJ1b4VajDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook:\n",
        "\n",
        "1. Get our data and split it into a training and test set.\n",
        "2. Implement a ranking model.\n",
        "3. Fit and evaluate it."
      ],
      "metadata": {
        "id": "AiKeLfa6anty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing and installing modules and libraries"
      ],
      "metadata": {
        "id": "D5a15gDTauZG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsPUGz5oaE8k"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "reny4uMvbRaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_recommenders as tfrs"
      ],
      "metadata": {
        "id": "kXXVphh-bTt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = tfds.load(\"movielens/100k-ratings\",split=\"train\")\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"user_rating\": x[\"user_rating\"]\n",
        "})"
      ],
      "metadata": {
        "id": "yKhUB2XcbZ8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b58efbcf-e3e6-43f3-8a18-b9dfb5fdbcde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before, we'll split the data by putting 80% of the ratings in the train set, and 20% in the test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "QM0IvjJTb0Zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(80_000)\n",
        "test = shuffled.skip(80_000).take(20_000)"
      ],
      "metadata": {
        "id": "wdYSa4Nmby7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also figure out unique user ids and movie titles present in the data.\n",
        "\n",
        "This is important because we need to be able to map the raw values of our categorical features to embedding vectors in our models. To do that, we need a vocabulary that maps a raw feature value to an integer in a contiguous range: this allows us to look up the corresponding embeddings in our embedding tables."
      ],
      "metadata": {
        "id": "0oa2ZQefcLOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_titles = ratings.batch(1_000_000).map(lambda x: x[\"movie_title\"])\n",
        "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
        "\n",
        "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
      ],
      "metadata": {
        "id": "2firgYc1cMtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing an Idea\n",
        "\n",
        "### Architecture\n",
        "\n",
        "Ranking models do not face the same efficiency constraints as retrieval models do, and so we have a little bit more freedom in our choice of architectures.\n",
        "\n",
        "A model composed of multiple stacked dense layers is a relatively common architecture for ranking tasks. We can implement it as follows:"
      ],
      "metadata": {
        "id": "-ywQiDuWcPoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MovielensModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.ranking_model: tf.keras.Model = RankingModel()\n",
        "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "      loss = tf.keras.losses.MeanSquaredError(),\n",
        "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        "    )\n",
        "\n",
        "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
        "    return self.ranking_model(\n",
        "        (features[\"user_id\"], features[\"movie_title\"]))\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    labels = features.pop(\"user_rating\")\n",
        "\n",
        "    rating_predictions = self(features)\n",
        "\n",
        "    # The task computes the loss and the metrics.\n",
        "    return self.task(labels=labels, predictions=rating_predictions)"
      ],
      "metadata": {
        "id": "GvxdELW3cbWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model takes user ids and movie titles, and outputs a predicted rating:\n",
        "\n"
      ],
      "metadata": {
        "id": "4Suu5GIgcfQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RankingModel()(([\"42\"], [\"One Flew Over the Cuckoo's Nest (1975)\"]))"
      ],
      "metadata": {
        "id": "sWJYS7Q2chI2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "33cebf9d-25fd-4325-bc85-41e2ada8f145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-66ef860cd6d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRankingModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"42\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"One Flew Over the Cuckoo's Nest (1975)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'RankingModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss and metrics\n",
        "\n",
        "The next component is the loss used to train our model. TFRS has several loss layers and tasks to make this easy.\n",
        "\n",
        "In this instance, we'll make use of the Ranking task object: a convenience wrapper that bundles together the loss function and metric computation.\n",
        "\n",
        "We'll use it together with the MeanSquaredError Keras loss in order to predict the ratings."
      ],
      "metadata": {
        "id": "9L-fG4umcz4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = tfrs.tasks.Ranking(\n",
        "    loss = tf.keras.losses.MeanSquaredError(),\n",
        "    metrics = [tf.keras.metrics.RootMeanSquaredError()]\n",
        ")"
      ],
      "metadata": {
        "id": "PPxd3Owkc2Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The full model\n",
        "\n",
        "We can now put it all together into a model. TFRS exposes a base model class (tfrs.models.Model) which streamlines bulding models: all we need to do is to set up the components in the __init__ method, and implement the compute_loss method, taking in the raw features and returning a loss value.\n",
        "\n",
        "The base model will then take care of creating the appropriate training loop to fit our model."
      ],
      "metadata": {
        "id": "tyeIAsBAfKcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MovielensModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.ranking_model: tf.keras.Model = RankingModel()\n",
        "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "      loss = tf.keras.losses.MeanSquaredError(),\n",
        "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        "    )\n",
        "\n",
        "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
        "    return self.ranking_model(\n",
        "        (features[\"user_id\"], features[\"movie_title\"]))\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    labels = features.pop(\"user_rating\")\n",
        "\n",
        "    rating_predictions = self(features)\n",
        "\n",
        "    # The task computes the loss and the metrics.\n",
        "    return self.task(labels=labels, predictions=rating_predictions)"
      ],
      "metadata": {
        "id": "1E-alTrKfO5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting and evaluating\n",
        "\n",
        "After defining the model, we can use standard Keras fitting and evaluation routines to fit and evaluate the model.\n",
        "\n",
        "Let's first instantiate the model."
      ],
      "metadata": {
        "id": "Mxd8m38DfSJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MovielensModel()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "P9WgZ2wJfVJP",
        "outputId": "ce22f621-6b19-4e62-be72-717ad2ba70be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-0536416ac940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMovielensModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdagrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-e2c5e80a1234>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranking_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRankingModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n\u001b[1;32m      7\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RankingModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
        "cached_test = test.batch(4096).cache()"
      ],
      "metadata": {
        "id": "UKw96w9JgDFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(cached_train, epochs=3)"
      ],
      "metadata": {
        "id": "TvrDBLd1f20y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(cached_test,return_dict=True)"
      ],
      "metadata": {
        "id": "a7RlZEpUgnV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The lower the RMSE metric, the more accurate our model is at predicting ratings."
      ],
      "metadata": {
        "id": "jkoH01r9g55B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Testing the ranking model\n",
        "\n",
        "Now we can test the ranking model by computing predictions for a set of movies and then rank these movies based on the predictions:"
      ],
      "metadata": {
        "id": "mfwPGjEIhADt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ratings = {}\n",
        "test_movie_titles = [\"M*A*S*H (1970)\", \"Dances with Wolves (1990)\", \"Speed (1994)\"]\n",
        "for movie_title in test_movie_titles:\n",
        "  test_ratings[movie_title] = model({\n",
        "      \"user_id\": np.array([\"42\"]),\n",
        "      \"movie_title\": np.array([movie_title])\n",
        "  })\n",
        "\n",
        "print(\"Ratings:\")\n",
        "for title, score in sorted(test_ratings.items(), key=lambda x: x[1], reverse=True):\n",
        "  print(f\"{title}: {score}\")"
      ],
      "metadata": {
        "id": "KbuN7v9mhDCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exporting for serving\n",
        "\n",
        "The model can be easily exported for serving:"
      ],
      "metadata": {
        "id": "ZMsbskkkhKz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, \"export\")"
      ],
      "metadata": {
        "id": "vMpjoMHNhMja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now load it back and perform predictions:\n",
        "\n"
      ],
      "metadata": {
        "id": "3_UdmM9IhQc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded = tf.saved_model.load(\"export\")\n",
        "\n",
        "loaded({\"user_id\": np.array([\"42\"]), \"movie_title\": [\"Speed (1994)\"]}).numpy()"
      ],
      "metadata": {
        "id": "xO5MRpNhhRx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert the model to TensorFLow Lite\n",
        "\n",
        "\n",
        "Although TensorFlow Recommenders is primarily designed to perform server-side recommendations, you can still convert the trained ranking model to TensorFLow Lite and run it on-device (for better user privacy privacy and lower latency)."
      ],
      "metadata": {
        "id": "xA_FiZ5-hVoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"export\")\n",
        "tflite_model = converter.convert()\n",
        "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "id": "WUZI946Xhbzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Test the model.\n",
        "if input_details[0][\"name\"] == \"serving_default_movie_title:0\":\n",
        "  interpreter.set_tensor(input_details[0][\"index\"], np.array([\"Speed (1994)\"]))\n",
        "  interpreter.set_tensor(input_details[1][\"index\"], np.array([\"42\"]))\n",
        "else:\n",
        "  interpreter.set_tensor(input_details[0][\"index\"], np.array([\"42\"]))\n",
        "  interpreter.set_tensor(input_details[1][\"index\"], np.array([\"Speed (1994)\"]))\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "rating = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(rating)"
      ],
      "metadata": {
        "id": "PIg7iHVNhiIb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}